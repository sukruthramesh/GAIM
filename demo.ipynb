{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93daa0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(OllamaLLM(model='gpt-oss:20b'), 'gpt-oss:20b'),\n",
       " (OllamaLLM(model='deepseek-r1:8b'), 'deepseek-r1:8b'),\n",
       " (OllamaLLM(model='ministral-3'), 'minstral-3'),\n",
       " (OllamaLLM(model='mistral:7b'), 'mistral:7b'),\n",
       " (OllamaLLM(model='phi3:mini'), 'phi3:mini'),\n",
       " (OllamaLLM(model='gemma2:9b'), 'gemma2:9b'),\n",
       " (OllamaLLM(model='starling-lm'), 'starling-1m')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_council.council import *\n",
    "from ai_council.generate_prompts import *\n",
    "import ast\n",
    "\n",
    "[(k[\"llm\"] , k[\"name\"]) for k in MODELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00dc2e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response by gpt-oss:20b\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "____________________________________________________\n",
      "Response by deepseek-r1:8b\n",
      "Sure, here's a joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything! ðŸ˜„\n",
      "____________________________________________________\n",
      "Response by minstral-3\n",
      "Here's one for you:\n",
      "\n",
      "**Why donâ€™t skeletons fight each other?**\n",
      "*Because they donâ€™t have the guts!* ðŸ˜„\n",
      "\n",
      "Want another? Iâ€™ve got plenty!\n",
      "____________________________________________________\n",
      "Response by mistral:7b\n",
      " Of course! Here's one for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "And here's another one, more tech-related:\n",
      "\n",
      "Why did the computer cold at work?\n",
      "\n",
      "It left its Windows open.\n",
      "\n",
      "I hope these made you smile!\n",
      "____________________________________________________\n",
      "Response by phi3:mini\n",
      "Why don't scientists trust atoms? Because they make up everything!\n",
      "____________________________________________________\n",
      "Response by gemma2:9b\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!  ðŸ˜‚ \n",
      "\n",
      "____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "for i,k in enumerate(MODELS):\n",
    "    if k['id'] == 'evaluator':\n",
    "        continue\n",
    "    print(f\"Response by {k[\"name\"]}\")\n",
    "    text = k[\"llm\"].invoke('Tell me a joke')\n",
    "    print(text)\n",
    "    print(\"____________________________________________________\")\n",
    "    responses.append(\n",
    "        {\n",
    "            \"response_id\" : f\"r_{i}\",\n",
    "            \"model_id\" : k[\"id\"],\n",
    "            \"text\" : text\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e368433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'response_id': 'r_0',\n",
       "  'model_id': 'expert_1',\n",
       "  'text': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"},\n",
       " {'response_id': 'r_1',\n",
       "  'model_id': 'expert_2',\n",
       "  'text': \"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything! ðŸ˜„\"},\n",
       " {'response_id': 'r_2',\n",
       "  'model_id': 'expert_3',\n",
       "  'text': \"Here's one for you:\\n\\n**Why donâ€™t skeletons fight each other?**\\n*Because they donâ€™t have the guts!* ðŸ˜„\\n\\nWant another? Iâ€™ve got plenty!\"},\n",
       " {'response_id': 'r_3',\n",
       "  'model_id': 'expert_4',\n",
       "  'text': \" Of course! Here's one for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\\nAnd here's another one, more tech-related:\\n\\nWhy did the computer cold at work?\\n\\nIt left its Windows open.\\n\\nI hope these made you smile!\"},\n",
       " {'response_id': 'r_4',\n",
       "  'model_id': 'expert_5',\n",
       "  'text': \"Why don't scientists trust atoms? Because they make up everything!\"},\n",
       " {'response_id': 'r_5',\n",
       "  'model_id': 'expert_6',\n",
       "  'text': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!  ðŸ˜‚ \\n\"}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20649725",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_prompt = [generate_scoring_prompt('Tell me a joke', str(response)) for response in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b928630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    SYSTEM: You are an impartial evaluator that scores candidate answers to a user prompt. Use the rubric provided and be objective. \n",
      "    Return only the JSON object described below and nothing else.\n",
      "\n",
      "    USER: Here is the ORIGINAL USER PROMPT:\n",
      "    Tell me a joke\n",
      "\n",
      "    Here is the CANDIDATE RESPONSE you must evaluate:\n",
      "    {'response_id': 'r_0', 'model_id': 'expert_1', 'text': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\"}\n",
      "\n",
      "    RUBRIC (score each 1-5; 5 = best):\n",
      "    - accuracy: Is the content factually correct given known, verifiable facts? (1 = many factual errors or hallucinations; 5 = fully accurate)\n",
      "    - completeness: Does it address all parts of the prompt? (1 = misses core parts; 5 = full coverage)\n",
      "    - grounding: Does the response cite or reference verifiable sources or show evidence/reasoning that can be checked? (1 = unsupported claims; 5 = well-grounded)\n",
      "    - reasoning: Are the logical steps coherent and correct? (1 = flawed reasoning; 5 = sound stepwise logic)\n",
      "    - clarity: Is it readable, appropriately toned, and well-structured? (1 = confusing; 5 = clear & concise)\n",
      "\n",
      "    Also provide a one-sentence justification for the total score.\n",
      "\n",
      "    Return JSON only with these fields:\n",
      "    {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": int,\n",
      "        \"completeness\": int,\n",
      "        \"grounding\": int,\n",
      "        \"reasoning\": int,\n",
      "        \"clarity\": int\n",
      "    },\n",
      "    \"confidence_estimate\": float, # 0.0-1.0; your best estimate of how confident you are\n",
      "    \"justification\": \"one-sentence justification\"\n",
      "    }\n",
      "\n",
      "    Notes:\n",
      "    - Score numerically and be conservative: penalize minor hallucinations or unsupported numeric claims.\n",
      "    - Do not refer to model names, internals, or policies in your justification.\n",
      "\n",
      "    \n",
      "\n",
      "    SYSTEM: You are an impartial evaluator that scores candidate answers to a user prompt. Use the rubric provided and be objective. \n",
      "    Return only the JSON object described below and nothing else.\n",
      "\n",
      "    USER: Here is the ORIGINAL USER PROMPT:\n",
      "    Tell me a joke\n",
      "\n",
      "    Here is the CANDIDATE RESPONSE you must evaluate:\n",
      "    {'response_id': 'r_1', 'model_id': 'expert_2', 'text': \"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything! ðŸ˜„\"}\n",
      "\n",
      "    RUBRIC (score each 1-5; 5 = best):\n",
      "    - accuracy: Is the content factually correct given known, verifiable facts? (1 = many factual errors or hallucinations; 5 = fully accurate)\n",
      "    - completeness: Does it address all parts of the prompt? (1 = misses core parts; 5 = full coverage)\n",
      "    - grounding: Does the response cite or reference verifiable sources or show evidence/reasoning that can be checked? (1 = unsupported claims; 5 = well-grounded)\n",
      "    - reasoning: Are the logical steps coherent and correct? (1 = flawed reasoning; 5 = sound stepwise logic)\n",
      "    - clarity: Is it readable, appropriately toned, and well-structured? (1 = confusing; 5 = clear & concise)\n",
      "\n",
      "    Also provide a one-sentence justification for the total score.\n",
      "\n",
      "    Return JSON only with these fields:\n",
      "    {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": int,\n",
      "        \"completeness\": int,\n",
      "        \"grounding\": int,\n",
      "        \"reasoning\": int,\n",
      "        \"clarity\": int\n",
      "    },\n",
      "    \"confidence_estimate\": float, # 0.0-1.0; your best estimate of how confident you are\n",
      "    \"justification\": \"one-sentence justification\"\n",
      "    }\n",
      "\n",
      "    Notes:\n",
      "    - Score numerically and be conservative: penalize minor hallucinations or unsupported numeric claims.\n",
      "    - Do not refer to model names, internals, or policies in your justification.\n",
      "\n",
      "    \n",
      "\n",
      "    SYSTEM: You are an impartial evaluator that scores candidate answers to a user prompt. Use the rubric provided and be objective. \n",
      "    Return only the JSON object described below and nothing else.\n",
      "\n",
      "    USER: Here is the ORIGINAL USER PROMPT:\n",
      "    Tell me a joke\n",
      "\n",
      "    Here is the CANDIDATE RESPONSE you must evaluate:\n",
      "    {'response_id': 'r_2', 'model_id': 'expert_3', 'text': \"Here's one for you:\\n\\n**Why donâ€™t skeletons fight each other?**\\n*Because they donâ€™t have the guts!* ðŸ˜„\\n\\nWant another? Iâ€™ve got plenty!\"}\n",
      "\n",
      "    RUBRIC (score each 1-5; 5 = best):\n",
      "    - accuracy: Is the content factually correct given known, verifiable facts? (1 = many factual errors or hallucinations; 5 = fully accurate)\n",
      "    - completeness: Does it address all parts of the prompt? (1 = misses core parts; 5 = full coverage)\n",
      "    - grounding: Does the response cite or reference verifiable sources or show evidence/reasoning that can be checked? (1 = unsupported claims; 5 = well-grounded)\n",
      "    - reasoning: Are the logical steps coherent and correct? (1 = flawed reasoning; 5 = sound stepwise logic)\n",
      "    - clarity: Is it readable, appropriately toned, and well-structured? (1 = confusing; 5 = clear & concise)\n",
      "\n",
      "    Also provide a one-sentence justification for the total score.\n",
      "\n",
      "    Return JSON only with these fields:\n",
      "    {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": int,\n",
      "        \"completeness\": int,\n",
      "        \"grounding\": int,\n",
      "        \"reasoning\": int,\n",
      "        \"clarity\": int\n",
      "    },\n",
      "    \"confidence_estimate\": float, # 0.0-1.0; your best estimate of how confident you are\n",
      "    \"justification\": \"one-sentence justification\"\n",
      "    }\n",
      "\n",
      "    Notes:\n",
      "    - Score numerically and be conservative: penalize minor hallucinations or unsupported numeric claims.\n",
      "    - Do not refer to model names, internals, or policies in your justification.\n",
      "\n",
      "    \n",
      "\n",
      "    SYSTEM: You are an impartial evaluator that scores candidate answers to a user prompt. Use the rubric provided and be objective. \n",
      "    Return only the JSON object described below and nothing else.\n",
      "\n",
      "    USER: Here is the ORIGINAL USER PROMPT:\n",
      "    Tell me a joke\n",
      "\n",
      "    Here is the CANDIDATE RESPONSE you must evaluate:\n",
      "    {'response_id': 'r_3', 'model_id': 'expert_4', 'text': \" Of course! Here's one for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\\nAnd here's another one, more tech-related:\\n\\nWhy did the computer cold at work?\\n\\nIt left its Windows open.\\n\\nI hope these made you smile!\"}\n",
      "\n",
      "    RUBRIC (score each 1-5; 5 = best):\n",
      "    - accuracy: Is the content factually correct given known, verifiable facts? (1 = many factual errors or hallucinations; 5 = fully accurate)\n",
      "    - completeness: Does it address all parts of the prompt? (1 = misses core parts; 5 = full coverage)\n",
      "    - grounding: Does the response cite or reference verifiable sources or show evidence/reasoning that can be checked? (1 = unsupported claims; 5 = well-grounded)\n",
      "    - reasoning: Are the logical steps coherent and correct? (1 = flawed reasoning; 5 = sound stepwise logic)\n",
      "    - clarity: Is it readable, appropriately toned, and well-structured? (1 = confusing; 5 = clear & concise)\n",
      "\n",
      "    Also provide a one-sentence justification for the total score.\n",
      "\n",
      "    Return JSON only with these fields:\n",
      "    {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": int,\n",
      "        \"completeness\": int,\n",
      "        \"grounding\": int,\n",
      "        \"reasoning\": int,\n",
      "        \"clarity\": int\n",
      "    },\n",
      "    \"confidence_estimate\": float, # 0.0-1.0; your best estimate of how confident you are\n",
      "    \"justification\": \"one-sentence justification\"\n",
      "    }\n",
      "\n",
      "    Notes:\n",
      "    - Score numerically and be conservative: penalize minor hallucinations or unsupported numeric claims.\n",
      "    - Do not refer to model names, internals, or policies in your justification.\n",
      "\n",
      "    \n",
      "\n",
      "    SYSTEM: You are an impartial evaluator that scores candidate answers to a user prompt. Use the rubric provided and be objective. \n",
      "    Return only the JSON object described below and nothing else.\n",
      "\n",
      "    USER: Here is the ORIGINAL USER PROMPT:\n",
      "    Tell me a joke\n",
      "\n",
      "    Here is the CANDIDATE RESPONSE you must evaluate:\n",
      "    {'response_id': 'r_4', 'model_id': 'expert_5', 'text': \"Why don't scientists trust atoms? Because they make up everything!\"}\n",
      "\n",
      "    RUBRIC (score each 1-5; 5 = best):\n",
      "    - accuracy: Is the content factually correct given known, verifiable facts? (1 = many factual errors or hallucinations; 5 = fully accurate)\n",
      "    - completeness: Does it address all parts of the prompt? (1 = misses core parts; 5 = full coverage)\n",
      "    - grounding: Does the response cite or reference verifiable sources or show evidence/reasoning that can be checked? (1 = unsupported claims; 5 = well-grounded)\n",
      "    - reasoning: Are the logical steps coherent and correct? (1 = flawed reasoning; 5 = sound stepwise logic)\n",
      "    - clarity: Is it readable, appropriately toned, and well-structured? (1 = confusing; 5 = clear & concise)\n",
      "\n",
      "    Also provide a one-sentence justification for the total score.\n",
      "\n",
      "    Return JSON only with these fields:\n",
      "    {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": int,\n",
      "        \"completeness\": int,\n",
      "        \"grounding\": int,\n",
      "        \"reasoning\": int,\n",
      "        \"clarity\": int\n",
      "    },\n",
      "    \"confidence_estimate\": float, # 0.0-1.0; your best estimate of how confident you are\n",
      "    \"justification\": \"one-sentence justification\"\n",
      "    }\n",
      "\n",
      "    Notes:\n",
      "    - Score numerically and be conservative: penalize minor hallucinations or unsupported numeric claims.\n",
      "    - Do not refer to model names, internals, or policies in your justification.\n",
      "\n",
      "    \n",
      "\n",
      "    SYSTEM: You are an impartial evaluator that scores candidate answers to a user prompt. Use the rubric provided and be objective. \n",
      "    Return only the JSON object described below and nothing else.\n",
      "\n",
      "    USER: Here is the ORIGINAL USER PROMPT:\n",
      "    Tell me a joke\n",
      "\n",
      "    Here is the CANDIDATE RESPONSE you must evaluate:\n",
      "    {'response_id': 'r_5', 'model_id': 'expert_6', 'text': \"Why don't scientists trust atoms?\\n\\nBecause they make up everything!  ðŸ˜‚ \\n\"}\n",
      "\n",
      "    RUBRIC (score each 1-5; 5 = best):\n",
      "    - accuracy: Is the content factually correct given known, verifiable facts? (1 = many factual errors or hallucinations; 5 = fully accurate)\n",
      "    - completeness: Does it address all parts of the prompt? (1 = misses core parts; 5 = full coverage)\n",
      "    - grounding: Does the response cite or reference verifiable sources or show evidence/reasoning that can be checked? (1 = unsupported claims; 5 = well-grounded)\n",
      "    - reasoning: Are the logical steps coherent and correct? (1 = flawed reasoning; 5 = sound stepwise logic)\n",
      "    - clarity: Is it readable, appropriately toned, and well-structured? (1 = confusing; 5 = clear & concise)\n",
      "\n",
      "    Also provide a one-sentence justification for the total score.\n",
      "\n",
      "    Return JSON only with these fields:\n",
      "    {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": int,\n",
      "        \"completeness\": int,\n",
      "        \"grounding\": int,\n",
      "        \"reasoning\": int,\n",
      "        \"clarity\": int\n",
      "    },\n",
      "    \"confidence_estimate\": float, # 0.0-1.0; your best estimate of how confident you are\n",
      "    \"justification\": \"one-sentence justification\"\n",
      "    }\n",
      "\n",
      "    Notes:\n",
      "    - Score numerically and be conservative: penalize minor hallucinations or unsupported numeric claims.\n",
      "    - Do not refer to model names, internals, or policies in your justification.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for prompt in scoring_prompt:\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce53192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response by gpt-oss:20b\n",
      "{\n",
      "  \"scores\": {\n",
      "    \"accuracy\": 5,\n",
      "    \"completeness\": 5,\n",
      "    \"grounding\": 1,\n",
      "    \"reasoning\": 5,\n",
      "    \"clarity\": 5\n",
      "  },\n",
      "  \"confidence_estimate\": 0.95,\n",
      "  \"justification\": \"The joke is factually correct, fully addresses the prompt, is clear and coherent, though it provides no explicit grounding.\"\n",
      "}\n",
      "{\n",
      "  \"scores\": {\n",
      "    \"accuracy\": 5,\n",
      "    \"completeness\": 5,\n",
      "    \"grounding\": 3,\n",
      "    \"reasoning\": 5,\n",
      "    \"clarity\": 5\n",
      "  },\n",
      "  \"confidence_estimate\": 0.95,\n",
      "  \"justification\": \"The answer provides a factually correct, complete, and clear joke that satisfies the prompt with no hallucinations.\"\n",
      "}\n",
      "{\"scores\":{\"accuracy\":5,\"completeness\":5,\"grounding\":3,\"reasoning\":5,\"clarity\":5},\"confidence_estimate\":0.95,\"justification\":\"The response delivers a clear, pun-based joke that fully satisfies the prompt.\"}\n",
      "{\"scores\":{\"accuracy\":5,\"completeness\":5,\"grounding\":1,\"reasoning\":1,\"clarity\":4},\"confidence_estimate\":0.95,\"justification\":\"The reply provides accurate, complete jokes but lacks any verifiable grounding or reasoning steps, yet remains clear and well-structured.\"}\n",
      "{\"scores\":{\"accuracy\":5,\"completeness\":5,\"grounding\":1,\"reasoning\":3,\"clarity\":5},\"confidence_estimate\":0.9,\"justification\":\"The response delivers a correct, clear joke that fully meets the prompt but offers no evidence or citations.\"}\n",
      "{\n",
      "  \"scores\": {\n",
      "    \"accuracy\": 5,\n",
      "    \"completeness\": 5,\n",
      "    \"grounding\": 1,\n",
      "    \"reasoning\": 5,\n",
      "    \"clarity\": 5\n",
      "  },\n",
      "  \"confidence_estimate\": 0.95,\n",
      "  \"justification\": \"The joke is factually correct, fully answers the prompt, but provides no sources or evidence, while remaining clear and logically coherent.\"\n",
      "}\n",
      "____________________________________________________\n",
      "Response by deepseek-r1:8b\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 1,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The response is a coherent, accurate joke but lacks grounding.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 4,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The response is accurate, complete, well-grounded, logically sound, and clear.\"\n",
      "}\n",
      "```\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 4,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The response is highly accurate, complete, clear, and logically structured as a joke, with minor grounding caveats.\"\n",
      "}\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 4,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 1,\n",
      "        \"reasoning\": 1,\n",
      "        \"clarity\": 4\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The response provides two appropriate jokes but lacks grounding and reasoning, scoring highest in accuracy and completeness.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 3,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 3,\n",
      "        \"clarity\": 4\n",
      "    },\n",
      "    \"confidence_estimate\": 0.9,\n",
      "    \"justification\": \"The response provides a complete and humorous joke, but lacks factual depth and relies on wordplay rather than complex reasoning.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "  \"scores\": {\n",
      "    \"accuracy\": 4,\n",
      "    \"completeness\": 5,\n",
      "    \"grounding\": 3,\n",
      "    \"reasoning\": 4,\n",
      "    \"clarity\": 4\n",
      "  },\n",
      "  \"confidence_estimate\": 0.9,\n",
      "  \"justification\": \"The response is mostly accurate and complete but relies on wordplay rather than factual evidence.\"\n",
      "}\n",
      "```\n",
      "____________________________________________________\n",
      "Response by minstral-3\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 5,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The joke is a classic, well-known pun with no factual errors, fully addresses the prompt, and is logically coherent, clear, and grounded in common cultural references.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 5,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The response perfectly fulfills the prompt with a well-known, coherent joke that is factually appropriate, clear, and requires no external grounding.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 5,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The joke is a classic, well-structured, and fully aligned with the prompt, requiring no factual verification or logical gaps.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 5,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The response perfectly fulfills the prompt with two well-known, appropriate jokes that are factually correct, logically coherent, and clearly presented.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 1,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The joke is a classic, well-structured, and logically coherent, though its humor relies on a playful metaphor without factual grounding.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 5,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The joke is a classic, well-structured pun with no factual errors, fully addressing the prompt for a joke and exhibiting perfect clarity and coherence.\"\n",
      "}\n",
      "```\n",
      "____________________________________________________\n",
      "Response by mistral:7b\n",
      " {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 0,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The response accurately answers the question with a humorous and well-structured joke. However, there are no cited sources or evidence to support its claim.\"\n",
      "    }\n",
      " {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 1,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The response accurately provides a joke as requested and covers all parts of the prompt. The reasoning is sound since a joke is meant to be humorous and this one does provide that effect. However, there's no evidence or grounding provided for the claim in the joke.\"\n",
      "}\n",
      " {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The response is accurate and complete, providing a joke in response to the prompt. It is well-structured and easy to understand. While there are no verifiable sources cited, the reasoning behind the punchline is sound.\"\n",
      "    }\n",
      " {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.98,\n",
      "    \"justification\": \"The content is fully accurate and addresses all parts of the prompt. Although some sources are not cited explicitly, the provided jokes do not rely on factual errors or unsupported claims.\"\n",
      "    }\n",
      " {\n",
      "  \"scores\": {\n",
      "      \"accuracy\": 5,\n",
      "      \"completeness\": 5,\n",
      "      \"grounding\": 1,\n",
      "      \"reasoning\": 5,\n",
      "      \"clarity\": 5\n",
      "  },\n",
      "  \"confidence_estimate\": 0.95,\n",
      "  \"justification\": \"The joke accurately and completely addresses the prompt with sound reasoning and clear, concise language, but it lacks any grounding in verifiable sources or evidence.\"\n",
      "}\n",
      " {\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 0,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 1.0,\n",
      "    \"justification\": \"The content is factually accurate and complete; it addresses all parts of the prompt with sound stepwise logic, demonstrating a clear and concise structure.\"\n",
      "    }\n",
      "____________________________________________________\n",
      "Response by phi3:mini\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 1,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.98,\n",
      "    \"justification\": \"The response is factually correct with appropriate humor and clear structure.\"\n",
      "}\n",
      "```json\n",
      "\n",
      "{\n",
      "\n",
      "    \"scores\": {\n",
      "\n",
      "        \"accuracy\": 5,\n",
      "\n",
      "        \"completeness\": 5,\n",
      "\n",
      "        \"grounding\": 1,\n",
      "\n",
      "        \"reasoning\": 4,\n",
      "\n",
      "        \"clarity\": 5\n",
      "\n",
      "    },\n",
      "\n",
      "    \"confidence_estimate\": 0.95,\n",
      "\n",
      "    \"justification\": \"The response effectively addresses all parts of the prompt and is clear and concise but lacks verifiable sources or evidence to support it.\"\n",
      "\n",
      "}\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "{\n",
      "  \"scores\": {\n",
      "      \"accuracy\": 3, # The joke is generally accurate but plays on the pun between 'skeletons' and 'guts', which could be misleading without context of ghost stories where skeletons might not have souls.\n",
      "      \"completeness\": 4, # While it responds to part one of the prompt by providing a joke related to fighting with something unrelated (skeletons), it invites another directly instead of commenting on or expanding upon the first response.\n",
      "      \"grounding\": 1, # There are no references made within this content that can be checked for verifiable sources about skeleton lore and humor regarding internal organs being 'guts'.\n",
      "      \"reasoning\": 4, # The joke presents a pun with coherent logic but lacks deeper reasoning or setup typical of many jokes.\n",
      "      \"clarity\": 5 # The text is easily readable, appropriately toned (light-hearted), and well-structured for humor delivery in this format without offending sensitivities commonly associated with such topics as internal organs being referred to colloquially as 'guts'.\n",
      "    },\n",
      "  \"confidence_estimate\": 0.85, # The response appears mostly appropriate but includes a play on words that may not be universally understood and could slightly mislead without context for such humor references in folklore or ghost stories related to skeletons.\n",
      "  \"justification\": \"The candidate provided an accurate joke with good logical structure while inviting another, yet lacks grounding evidence which reduces the confidence score.\"\n",
      "}\n",
      "\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 3,\n",
      "        \"completeness\": 2,\n",
      "        \"grounding\": 1,\n",
      "        \"reasoning\": 4,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.85,\n",
      "    \"justification\": \"The jokes are mostly clear and structured well; however, the first joke is a factual error as it misrepresents scientific principles.\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "```json\n",
      "{\n",
      "  \"scores\": {\n",
      "      \"accuracy\": 5,\n",
      "      \"completeness\": 5,\n",
      "      \"grounding\": 5,\n",
      "      \"reasoning\": 5,\n",
      "      \"clarity\": 5\n",
      "  },\n",
      "  \"confidence_estimate\": 0.98, # Given the high score in all categories and clear humor without any factual errors or hallucinations\n",
      "  \"justification\": \"The joke is accurate, complete addresses the prompt directly with a play on words that demonstrates reasoning through clever wordplay while maintaining clarity.\"\n",
      "}\n",
      "```\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 4, # Assuming the joke is a play on words and not requiring external grounding to understand its humor.\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The response provides an accurate and complete joke with sound reasoning behind the punchline; however, its grounding could be improved by providing context for wordplay.\"\n",
      "}\n",
      "____________________________________________________\n",
      "Response by gemma2:9b\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 4,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.95,\n",
      "    \"justification\": \"The joke is well-structured, understandable, and presents a humorous play on words.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 4,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.98,\n",
      "    \"justification\": \"The joke is told clearly and accurately, though the grounding could be stronger with a mention of the scientific concept being referenced.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.98,\n",
      "    \"justification\": \"The joke is appropriate and well-structured, though it lacks grounding in any verifiable source.\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 1,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.98,\n",
      "    \"justification\": \"The response is well-structured, clear, and provides two jokes that are factually accurate and logically sound.\"\n",
      "}\n",
      "```\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 5,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.98,\n",
      "    \"justification\": \"The joke is factually sound and clearly presented, though it lacks a source or explanation for its humor.\"\n",
      "}  \n",
      "\n",
      "{\n",
      "    \"scores\": {\n",
      "        \"accuracy\": 5,\n",
      "        \"completeness\": 5,\n",
      "        \"grounding\": 3,\n",
      "        \"reasoning\": 4,\n",
      "        \"clarity\": 5\n",
      "    },\n",
      "    \"confidence_estimate\": 0.98,\n",
      "    \"justification\": \"The joke is well-structured, understandable, and tells a complete humorous story.\"\n",
      "}  \n",
      "\n",
      "____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "scoring_matrix = {}\n",
    "for i,k in enumerate(MODELS):\n",
    "    if k[\"id\"] == \"evaluator\":\n",
    "        continue\n",
    "    temp_dict = {}\n",
    "    # if k[\"name\"] == \"deepseek-r1:8b\":\n",
    "    #     continue\n",
    "    print(f\"Response by {k[\"name\"]}\")\n",
    "    for i in range(len(scoring_prompt)):\n",
    "        text = k[\"llm\"].invoke(scoring_prompt[i])\n",
    "        print(text)\n",
    "        json_response = ast.literal_eval('{'+ extract_first_curly_balanced(text) + '}')\n",
    "        json_response[\"total\"] = sum([WEIGHTS[j] * json_response['scores'][j] for j in WEIGHTS])\n",
    "        temp_dict[responses[i]['response_id']] = json_response\n",
    "    scoring_matrix[k[\"name\"]] = temp_dict\n",
    "    print(\"____________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf40cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"deepseek-r1:8b\": {\n",
      "        \"r_0\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response is a coherent, accurate joke but lacks grounding.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        },\n",
      "        \"r_1\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response is accurate, complete, well-grounded, logically sound, and clear.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 4,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.8\n",
      "        },\n",
      "        \"r_2\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response is highly accurate, complete, clear, and logically structured as a joke, with minor grounding caveats.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 4,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.8\n",
      "        },\n",
      "        \"r_3\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response provides two appropriate jokes but lacks grounding and reasoning, scoring highest in accuracy and completeness.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 4,\n",
      "                \"clarity\": 4,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 1\n",
      "            },\n",
      "            \"total\": 3.1999999999999997\n",
      "        },\n",
      "        \"r_4\": {\n",
      "            \"confidence_estimate\": 0.9,\n",
      "            \"justification\": \"The response provides a complete and humorous joke, but lacks factual depth and relies on wordplay rather than complex reasoning.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 3,\n",
      "                \"clarity\": 4,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 3\n",
      "            },\n",
      "            \"total\": 3.55\n",
      "        },\n",
      "        \"r_5\": {\n",
      "            \"confidence_estimate\": 0.9,\n",
      "            \"justification\": \"The response is mostly accurate and complete but relies on wordplay rather than factual evidence.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 4,\n",
      "                \"clarity\": 4,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 4\n",
      "            },\n",
      "            \"total\": 4.05\n",
      "        }\n",
      "    },\n",
      "    \"gemma2:9b\": {\n",
      "        \"r_0\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The joke is well-structured, understandable, and presents a humorous play on words.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 4\n",
      "            },\n",
      "            \"total\": 4.45\n",
      "        },\n",
      "        \"r_1\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The joke is told clearly and accurately, though the grounding could be stronger with a mention of the scientific concept being referenced.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 4\n",
      "            },\n",
      "            \"total\": 4.45\n",
      "        },\n",
      "        \"r_2\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The joke is appropriate and well-structured, though it lacks grounding in any verifiable source.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.6\n",
      "        },\n",
      "        \"r_3\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The response is well-structured, clear, and provides two jokes that are factually accurate and logically sound.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        },\n",
      "        \"r_4\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The joke is factually sound and clearly presented, though it lacks a source or explanation for its humor.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.6\n",
      "        },\n",
      "        \"r_5\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The joke is well-structured, understandable, and tells a complete humorous story.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 4\n",
      "            },\n",
      "            \"total\": 4.45\n",
      "        }\n",
      "    },\n",
      "    \"gpt-oss:20b\": {\n",
      "        \"r_0\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The joke is factually correct, fully addresses the prompt, is clear and coherent, though it provides no explicit grounding.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        },\n",
      "        \"r_1\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The answer provides a factually correct, complete, and clear joke that satisfies the prompt with no hallucinations.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.6\n",
      "        },\n",
      "        \"r_2\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response delivers a clear, pun-based joke that fully satisfies the prompt.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.6\n",
      "        },\n",
      "        \"r_3\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The reply provides accurate, complete jokes but lacks any verifiable grounding or reasoning steps, yet remains clear and well-structured.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 4,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 1\n",
      "            },\n",
      "            \"total\": 3.55\n",
      "        },\n",
      "        \"r_4\": {\n",
      "            \"confidence_estimate\": 0.9,\n",
      "            \"justification\": \"The response delivers a correct, clear joke that fully meets the prompt but offers no evidence or citations.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 3\n",
      "            },\n",
      "            \"total\": 3.9\n",
      "        },\n",
      "        \"r_5\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The joke is factually correct, fully answers the prompt, but provides no sources or evidence, while remaining clear and logically coherent.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        }\n",
      "    },\n",
      "    \"minstral-3\": {\n",
      "        \"r_0\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The joke is a classic, well-known pun with no factual errors, fully addresses the prompt, and is logically coherent, clear, and grounded in common cultural references.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 5,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 5.0\n",
      "        },\n",
      "        \"r_1\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The response perfectly fulfills the prompt with a well-known, coherent joke that is factually appropriate, clear, and requires no external grounding.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 5,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 5.0\n",
      "        },\n",
      "        \"r_2\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The joke is a classic, well-structured, and fully aligned with the prompt, requiring no factual verification or logical gaps.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 5,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 5.0\n",
      "        },\n",
      "        \"r_3\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The response perfectly fulfills the prompt with two well-known, appropriate jokes that are factually correct, logically coherent, and clearly presented.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 5,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 5.0\n",
      "        },\n",
      "        \"r_4\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The joke is a classic, well-structured, and logically coherent, though its humor relies on a playful metaphor without factual grounding.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        },\n",
      "        \"r_5\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The joke is a classic, well-structured pun with no factual errors, fully addressing the prompt for a joke and exhibiting perfect clarity and coherence.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 5,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 5.0\n",
      "        }\n",
      "    },\n",
      "    \"mistral:7b\": {\n",
      "        \"r_0\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The response accurately answers the question with a humorous and well-structured joke. However, there are no cited sources or evidence to support its claim.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 0,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.0\n",
      "        },\n",
      "        \"r_1\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response accurately provides a joke as requested and covers all parts of the prompt. The reasoning is sound since a joke is meant to be humorous and this one does provide that effect. However, there's no evidence or grounding provided for the claim in the joke.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        },\n",
      "        \"r_2\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response is accurate and complete, providing a joke in response to the prompt. It is well-structured and easy to understand. While there are no verifiable sources cited, the reasoning behind the punchline is sound.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.6\n",
      "        },\n",
      "        \"r_3\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The content is fully accurate and addresses all parts of the prompt. Although some sources are not cited explicitly, the provided jokes do not rely on factual errors or unsupported claims.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 3,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.6\n",
      "        },\n",
      "        \"r_4\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The joke accurately and completely addresses the prompt with sound reasoning and clear, concise language, but it lacks any grounding in verifiable sources or evidence.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        },\n",
      "        \"r_5\": {\n",
      "            \"confidence_estimate\": 1.0,\n",
      "            \"justification\": \"The content is factually accurate and complete; it addresses all parts of the prompt with sound stepwise logic, demonstrating a clear and concise structure.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 0,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.0\n",
      "        }\n",
      "    },\n",
      "    \"phi3:mini\": {\n",
      "        \"r_0\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The response is factually correct with appropriate humor and clear structure.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.2\n",
      "        },\n",
      "        \"r_1\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response effectively addresses all parts of the prompt and is clear and concise but lacks verifiable sources or evidence to support it.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 4\n",
      "            },\n",
      "            \"total\": 4.05\n",
      "        },\n",
      "        \"r_2\": {\n",
      "            \"confidence_estimate\": 0.85,\n",
      "            \"justification\": \"The candidate provided an accurate joke with good logical structure while inviting another, yet lacks grounding evidence which reduces the confidence score.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 3,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 4,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 4\n",
      "            },\n",
      "            \"total\": 3.0999999999999996\n",
      "        },\n",
      "        \"r_3\": {\n",
      "            \"confidence_estimate\": 0.85,\n",
      "            \"justification\": \"The jokes are mostly clear and structured well; however, the first joke is a factual error as it misrepresents scientific principles.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 3,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 2,\n",
      "                \"grounding\": 1,\n",
      "                \"reasoning\": 4\n",
      "            },\n",
      "            \"total\": 2.5999999999999996\n",
      "        },\n",
      "        \"r_4\": {\n",
      "            \"confidence_estimate\": 0.98,\n",
      "            \"justification\": \"The joke is accurate, complete addresses the prompt directly with a play on words that demonstrates reasoning through clever wordplay while maintaining clarity.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 5,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 5.0\n",
      "        },\n",
      "        \"r_5\": {\n",
      "            \"confidence_estimate\": 0.95,\n",
      "            \"justification\": \"The response provides an accurate and complete joke with sound reasoning behind the punchline; however, its grounding could be improved by providing context for wordplay.\",\n",
      "            \"scores\": {\n",
      "                \"accuracy\": 5,\n",
      "                \"clarity\": 5,\n",
      "                \"completeness\": 5,\n",
      "                \"grounding\": 4,\n",
      "                \"reasoning\": 5\n",
      "            },\n",
      "            \"total\": 4.8\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pretty_print_json(scoring_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64723aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gaim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
